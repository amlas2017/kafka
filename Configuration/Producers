// Maitriser le parametrage des producers kafka    ------------------------>   https://blog.zenika.com/2020/11/04/maitriser-le-parametrage-des-producers-kafka/

// Batch Linger
La configuration linger.ms définit le temps minimum que le producer va attendre avant d’envoyer un batch. Cette propriété laisse donc le temps aux messages de 
s’accumuler côté producer avant envoi, pour limiter le nombre d’appels réseau vers le broker et gagner en performance globale. Tant que la durée définie dans 
linger.ms ne s’est pas écoulée, le producer n’enverra pas le batch, à condition que le batch ne dépasse pas la taille maximale autorisée (voir batch.size ci-dessous).
Par défaut, cette propriété est configurée à 0 (on n’attend pas que les batchs se remplissent avant envoi). Pour connaître la valeur à configurer, des tests de 
performance doivent être effectués avec la volumétrie et la fréquence cible des données qui vont transiter par ce topic. Ces tests, en combinaison avec le batch.size, 
permettront d’assurer un taux de traitement maximum. 


// Même si nous configurons les brokers dans la configuration la plus fiable possible, le système dans son ensemble peut toujours 
perdre accidentellement des données si nous ne configurons pas les producteurs pour qu'ils soient également fiables.

// Accusé de réception de messages: acks 

Properties config = new Properties();
config.put("client.id", InetAddress.getLocalHost().getHostName());
config.put("bootstrap.servers", "host1:9092,host2:9092");
config.put("acks", "all");        <--------------------------------------------
new KafkaProducer<K, V>(config);

- acks=0 signifie qu'un message est considéré comme écrit avec succès dans Kafka si le producer a réussi à l'envoyer sur le réseau.
On obtiendrait toujours des erreurs si l'objet que vous envoyez ne peut pas être sérialisé ou si la carte réseau a échoué, mais on 
n'aurait aucune erreur si la partition est hors ligne ou si l'ensemble du cluster Kafka est hors ligne. Cela signifie que même dans 
le cas prévu d'une élection du Leader, le producteur perdra des messages car il ne saura pas que le Leader n'est pas disponible 
pendant qu'un nouveau Leader est élu.
---> L'exécution avec acks = 0 est très rapide (c'est pourquoi vous voyez beaucoup de repères avec cette configuration). 
     On peut obtenir un débit incroyable et utiliser la majeure partie de la bande passante, mais on est assuré de perdre certains 
     messages si on choisit cette route.
     
- acks=1 signifie que le leader enverra un accusé de réception ou une erreur au moment où il recevra le message et l'écrira dans le fichier de données de partition (mais pas nécessairement synchronisé sur le disque). Cela signifie que dans des circonstances normales d'élection de leader, votre producteur recevra LeaderNotAvailableException pendant qu'un leader est élu, et si le producteur gère correctement cette erreur (voir la section suivante), il réessayera d'envoyer le message et le message arrivera en toute sécurité au Nouveau
Leader. On peut perdre des données si le Leader se bloque et que certains messages qui ont été écrits avec succès au Leader et 
reconnus n'ont pas été répliqués vers les Followers avant le plantage.  

- acks=all signifie que le Leader attendra que toutes les répliques synchronisées reçoivent le message avant de renvoyer un 
accusé de réception ou une erreur. En conjonction avec la configuration min.insync.replica sur le Broker, cela nous permet de 
contrôler le nombre de répliques qui reçoivent le message avant qu'il ne soit reconnu. Il s'agit de l'option la plus sûre: le 
producteur n'arrêtera pas d'envoyer le message avant qu'il ne soit pleinement engagé. Il s'agit également de l'option la plus 
lente: le producer attend que toutes les répliques reçoivent tous les messages avant de pouvoir marquer le lot de messages 
comme «terminé» et continuer. Les effets peuvent être atténués en utilisant le mode asynchrone pour le producer et en envoyant 
des lots plus importants, mais cette option vous permettra généralement de réduire le débit.





