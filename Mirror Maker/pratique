// ---->     https://medium.com/real-time-streaming/apache-kafka-mirror-maker-1400efeca94d

// MirrorMaker (réplicateur inter-cluster intégré de Kafka est appelé MirrorMaker) est un outil permettant de mettre en miroir des données entre deux datacenters. 
A la base, il s'agit d'une collection de consumers (appelés flux dans la documentation MirrorMaker, pour des raisons historiques), qui font tous partie du même 
groupe de consumers et lisent les données de l'ensemble des topics que vous avez choisi de répliquer.
Chaque processus MirrorMaker a un seul producer. Le flux de travail est assez simple: MirrorMaker exécute un thread pour chaque consumer. 
Chaque consumer consomme des événements des topics et des partitions qui lui ont été affectées sur le cluster source et utilise le producer partagé pour envoyer ces 
événements au cluster cible.

// MirrorMaker permet de créer un “miroir” d’un cluster Kafka entier. Sur papier, cela semble être un bon outil pour répliquer un cluster, néanmoins il possède 
plusieurs défauts. Pour en citer quelques un : les topics miroirs sont créés avec une configuration par défaut, les ACLs (Access Control Lists) ne sont pas répliqués,
les messages sont re-partitionnés avec la “DefaultPartitionner” , etc.
---> MirrorMaker 2.0 se base sur Kafka Connect afin de répliquer le mieux possible un cluster Kafka.

// TP kafka/MirrorMaker avec Docker ---->  https://github.com/framiere/mirror-maker-docker-example

version: '2'
services:
  zookeeper-source:
    image: confluentinc/cp-zookeeper:4.0.0
    hostname: zookeeper-source
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181

  kafka-source:
    image: confluentinc/cp-kafka:4.0.0
    hostname: kafka-source
    depends_on:
      - zookeeper-source
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: 'zookeeper-source:2181'
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka-source:9092      
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1

  zookeeper-destination:
    image: confluentinc/cp-zookeeper:4.0.0
    hostname: zookeeper-destination
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181

  kafka-destination:
    image: confluentinc/cp-kafka:4.0.0
    hostname: kafka-destination
    depends_on:
      - zookeeper-destination
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: 'zookeeper-destination:2181'
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka-destination:9092      
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1            

  topic-creation:
    image: confluentinc/cp-kafka:4.0.0
    command: bash -c "cub kafka-ready -z zookeeper-source:2181 1 30 && kafka-topics --zookeeper zookeeper-source:2181 --create --topic topic-to-mirror --partitions 10 --replication-factor 1"
    depends_on:
      - zookeeper-source

  dummy-generation:
    image: confluentinc/cp-kafka:4.0.0
    command: bash -c "cub kafka-ready -z zookeeper-source:2181 1 30 && sleep 5 && seq 10000 | kafka-console-producer --broker-list kafka-source:9092 --topic topic-to-mirror"
    depends_on:
      - zookeeper-source
      - kafka-source

  mirror-maker:
    image: confluentinc/cp-kafka:4.0.0
    volumes:
      - ./consumer.cfg:/etc/consumer.cfg
      - ./producer.cfg:/etc/producer.cfg
    command: bash -c "cub kafka-ready -z zookeeper-source:2181 1 30 && cub kafka-ready -z zookeeper-destination:2181 1 30 && kafka-mirror-maker --consumer.config /etc/consumer.cfg --producer.config /etc/producer.cfg --whitelist topic-to-mirror --num.streams 1"
    depends_on:
      - kafka-source
      - kafka-destination
      - zookeeper-destination
