https://data-flair.training/blogs/kafka-tutorials-home/


                        ***************************************************************************************************
                                                            Listing Kafka Consumers
                        ***************************************************************************************************
-     https://www.baeldung.com/ops/listing-kafka-consumers


=======================================================================================================================================================================

// Liste de brokers: --->     echo dump | nc localhost 2181 | grep brokers

// Afficher plus d'éléments sur le consumer (key, value, offset...) dans la console:
$ bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic test --property print.key=true 
   --property print.value=true --from-beginning

// Fichier log kafka sont stockés dans   .../kafka/logs/server.log

// Supprimer un topic   ---->  https://sparkbyexamples.com/kafka/kafka-delete-topic/

// Numéro du dernier offset:

i/ ------> commandes kafka:
bin/kafka-run-class.sh kafka.tools.GetOffsetShell --broker-list localhost:9092 --topic test -time -1 --partitions 0

test:0:18

ii/------> commandes zookeeper******************

/usr/lib/zookeeper/bin/zkCli.sh -server localhost:2181 get /consumers/spark-streaming-consumer/offsets/test/0

------> lag entre offsets Kafka et en consumer (Spark Streaming consumer):
bin/kafka-consumer-offset-checker.sh --zookeeper localhost:2181 --topic test --group spark-streaming-consumer


----------------------------------------------------Spark Streaming----------------------------------------------------
Deux approaches pour integrer Kafka à Spark:
         ---> Receiver-based approach
         ---> Direct approach  <------ avantageux

Caractéristiques:
- Parallelism and throughput:
 Le nombre de partitions dans RDD est défini par le nombre de partitions dans un topic Kafka. Ces partitions RDD lisent les 
messages des partitions du topic Kafka en parallèle. En bref, Spark Streaming crée une partition RDD égale au nombre de partitions
Kafka disponibles pour consommer des données en parallèle, ce qui augmente le débit.
 
- No write-ahead log: 
L'approche directe n'utilise pas de log d'écriture anticipée pour éviter la perte de données. Le log d'écriture anticipée 
entraînait un stockage supplémentaire et la possibilité de conduire à un traitement des données en double dans quelques cas. 
L'approche directe, à la place, lit les données directement à partir de Kafka et valide le décalage des messages traités au point
de contrôle. En cas d'échec, Spark sait par où commencer.

- No Zookeeper: 
Par défaut, l'approche directe n'utilise pas Zookeeper pour valider l'Offeset consommé par Spark.Spark utilise un mécanisme de 
point de contrôle pour gérer la perte de données et pour démarrer l'exécution à partir du dernier point d'exécution en cas 
d'échec.Cependant, la validation de décalage basée sur Zookeeper peut être effectuée à l'aide de Curator Client.
 Apache Curator est un client Java de Apache Zookeeper , le service de coordination populaire pour les applications distribuées.
 
- Exactly one processing: 
L'approche directe offre la possibilité de réaliser exactement un traitement, ce qui signifie qu'aucune donnée n'est traitée 
deux fois et aucune donnée n'est perdue.Pour ce faire, utilisez le point de contrôle géré par l'application Spark Streaming qui 
indique à l'application Spark Streaming où commencer en cas d'échec.
 
------------------------------------------------------------Kafka Connect----------------------------------------------------------------------------------
Exemple Kafka Connect & Kafka Schema registry & sqlite database -------> page 164 Building Data DStream Application with Kafka.
-----------------------------------------------------------------------------------------------------------------------------------------------------------

// Modifier/Augmenter le nombre de partitions d'un topic:
      # kafka-topics.sh --zookeeper zoo1.example.com:2181/kafka-cluster  --alter --topic my-topic --partitions 16

// Réduire le nombre de partitions d'un topic:
Il n'est pas possible de réduire le nombre de partitions pour un topic.La raison pour laquelle cela n'est pas pris en charge est 
que la suppression d'une partition d'un topic entraînerait également la suppression d'une partie des données de ce topic, ce qui 
serait incohérent du point de vue du client.
De plus, il serait difficile d'essayer de redistribuer les données vers les partitions restantes et d'entraîner des messages hors
service.
-----> Si vous devez réduire le nombre de partitions, vous devrez supprimer le topic et le recréer.
 





