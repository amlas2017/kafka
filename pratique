https://data-flair.training/blogs/kafka-tutorials-home/

// Liste de brokers: --->     echo dump | nc localhost 2181 | grep brokers

// Supprimer un topic   ---->  https://sparkbyexamples.com/kafka/kafka-delete-topic/

// Numéro du dernier offset:

i/ ------> commandes kafka:
bin/kafka-run-class.sh kafka.tools.GetOffsetShell --broker-list localhost:9092 --topic test -time -1 --partitions 0

test:0:18

ii/------> commandes zookeeper******************

/usr/lib/zookeeper/bin/zkCli.sh -server localhost:2181 get /consumers/spark-streaming-consumer/offsets/test/0

------> lag entre offsets Kafka et en consumer (Spark Streaming consumer):
bin/kafka-consumer-offset-checker.sh --zookeeper localhost:2181 --topic test --group spark-streaming-consumer


----------------------------------------------------Spark Streaming----------------------------------------------------
Deux approaches pour integrer Kafka à Spark:
         ---> Receiver-based approach
         ---> Direct approach  <------ avantageux

Caractéristiques:
- Parallelism and throughput:
 Le nombre de partitions dans RDD est défini par le nombre de partitions dans un topic Kafka. Ces partitions RDD lisent les 
messages des partitions du topic Kafka en parallèle. En bref, Spark Streaming crée une partition RDD égale au nombre de partitions
Kafka disponibles pour consommer des données en parallèle, ce qui augmente le débit.
 
- No write-ahead log: 
L'approche directe n'utilise pas de log d'écriture anticipée pour éviter la perte de données. Le log d'écriture anticipée 
entraînait un stockage supplémentaire et la possibilité de conduire à un traitement des données en double dans quelques cas. 
L'approche directe, à la place, lit les données directement à partir de Kafka et valide le décalage des messages traités au point
de contrôle. En cas d'échec, Spark sait par où commencer.

- No Zookeeper: 
Par défaut, l'approche directe n'utilise pas Zookeeper pour valider l'Offeset consommé par Spark.Spark utilise un mécanisme de 
point de contrôle pour gérer la perte de données et pour démarrer l'exécution à partir du dernier point d'exécution en cas 
d'échec.Cependant, la validation de décalage basée sur Zookeeper peut être effectuée à l'aide de Curator Client.
 Apache Curator est un client Java de Apache Zookeeper , le service de coordination populaire pour les applications distribuées.
 
- Exactly one processing: 
 Direct approach provides opportunity to achieve exactly one processing, which means that no data is processed twice and no data is lost.
This is done using checkpoint maintained by Spark Streaming application which tells Spark Streaming application about where to start in case of failure.

------------------------------------------------------------Kafka Connect----------------------------------------------------------------------------------
Exemple Kafka Connect & Kafka Schema registry & sqlite database -------> page 164 Building Data DStream Application with Kafka
 





